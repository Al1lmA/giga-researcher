import sys
import os

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –∫–æ—Ä–Ω—é –ø—Ä–æ–µ–∫—Ç–∞
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..')))

import time
from gpt_researcher.config import Config
from gpt_researcher.master.functions import *
from gpt_researcher.context.compression import ContextCompressor
from gpt_researcher.memory import Memory
from modules.google import search_google
from loguru import logger
from langchain.prompts import PromptTemplate
from langchain_community.chat_models import GigaChat
import os
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough

class GPTResearcher:

    def __init__(self, query='', config_path=None, websocket=None):
        logger.info("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è GPTResearcher...")
        self.query = query
        self.agent = None
        self.role = None
        self.websocket = websocket
        self.cfg = Config(config_path)
        self.retriever = get_retriever(self.cfg.retriever)
        self.context = []
        self.memory = Memory(self.cfg.embedding_provider)
        logger.info("GPTResearcher —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω!")
        self.visited_urls = set()

    async def run(self, facts=''):

        logger.info(f"–ü–æ–∏—Å–∫ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ —Ç–µ–º–µ '{self.query}'")

        
        await stream_output("logs", f"–ü–æ–∏—Å–∫ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ —Ç–µ–º–µ '{self.query}'", self.websocket)
        await asyncio.sleep(1)
        
        self.agent, self.role = await choose_agent(self.query, self.cfg)
        
        await stream_output("logs", self.agent, self.websocket)
        await asyncio.sleep(1)
        try:
            self.context = await self.get_context_by_search(self.query)
        except Exception as e:
            logger.error("–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–±–æ—Ä–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏", e)
        try:
            report = await generate_report(query=self.query, context=self.context, facts=facts,
                                       agent_role_prompt=self.role,
                                       websocket=self.websocket, cfg=self.cfg)
        except Exception as e:
            logger.error("–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –æ—Ç—á–µ—Ç–∞", e)
        await asyncio.sleep(2)
        return report
    
    async def qa_run(self, question):

        logger.info(f"–ü–æ–∏—Å–∫ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ —Ç–µ–º–µ '{question}'")

        self.context = await self.get_context_by_search(question)

        answer = await get_answer(query=question, context=self.context, cfg=self.cfg)
        return answer


    async def get_context_by_search(self, query):

        context = []
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–æ–¥–∑–∞–ø—Ä–æ—Å–æ–≤
        sub_queries = await get_sub_queries(query, self.role, self.cfg) + [query]
        await stream_output("logs",
                            f"üß† –î–ª—è –ø–æ–∏—Å–∫–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –±—É–¥—É—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω—ã —Å–ª–µ–¥—É—é—â–∏–µ –∑–∞–ø—Ä–æ—Å—ã: {sub_queries}...",
                            self.websocket)
        await asyncio.sleep(0.5)
        
        try:
            for sub_query in sub_queries:
                await stream_output("logs", f"\nüîé –ü–æ–∏—Å–∫ –ø–æ –∑–∞–ø—Ä–æ—Å—É '{sub_query}'...", self.websocket)
                scraped_sites = await self.scrape_sites_by_query(sub_query)
                content = await self.get_similar_content_by_query(sub_query, scraped_sites)
                context.append(content)
        except Exception as er:
            logger.exception(er)
        return context

    async def get_new_urls(self, url_set_input):
        new_urls = []
        for url in url_set_input:
            if url not in self.visited_urls:
                await stream_output("logs", f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω –∏—Å—Ç–æ—á–Ω–∏–∫ –¥–ª—è –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è: {url}\n", self.websocket)
                await asyncio.sleep(0.5)
                self.visited_urls.add(url)
                new_urls.append(url)

        return new_urls

    async def scrape_sites_by_query(self, sub_query):

        retriever = self.retriever(sub_query)
        search_results = retriever.search(max_results=self.cfg.max_search_results_per_query)
        new_search_urls = await self.get_new_urls([url.get("href") for url in search_results])
        scraped_content_results = scrape_urls(new_search_urls, self.cfg)
        return scraped_content_results

    async def get_similar_content_by_query(self, query, pages):
        context_compressor = ContextCompressor(documents=pages, embeddings=self.memory.get_embeddings())
        return context_compressor.get_context(query, max_results=8)



    async def add_card_value_(self, org_name):
        try:
            card = {}
            keys = [
            '–ì–æ–¥ –æ—Å–Ω–æ–≤–∞–Ω–∏—è',
            '–¢–µ–ª–µ—Ñ–æ–Ω',
            'Email',
            '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤',
            '–ö–ª—é—á–µ–≤—ã–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏',
            '–°—Ñ–µ—Ä—ã –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è',
            '–û—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π —Å–∞–π—Ç']

            quest = [
                f'–ì–æ–¥ –æ—Å–Ω–æ–≤–∞–Ω–∏—è –∫–æ–º–ø–∞–Ω–∏–∏ {org_name}?',
                f'–ù–æ–º–µ—Ä —Ç–µ–ª–µ—Ñ–æ–Ω–∞ –∏–ª–∏ –≥–æ—Ä—è—á–∞—è –ª–∏–Ω–∏—è –∫–æ–º–ø–∞–Ω–∏–∏ {org_name}?', 
                f'–≠–ª–µ–∫—Ç—Ä–æ–Ω–Ω–∞—è –ø–æ—á—Ç–∞ –∏–ª–∏ Email –∫–æ–º–ø–∞–Ω–∏–∏ {org_name}?',
                f'–°–∫–æ–ª—å–∫–æ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ —Ä–∞–±–æ—Ç–∞–µ—Ç –≤ {org_name}?', 
                f'–ö–∞–∫–∏–µ –∫–ª—é—á–µ–≤—ã–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ –ø—Ä–∏–º–µ–Ω—è–µ—Ç –∫–æ–º–ø–∞–Ω–∏—è {org_name}?', 
                f'–ö–∞–∫–∞—è —Å—Ñ–µ—Ä–∞ –ø—Ä–∏–º–µ–Ω–∏—è –∫–æ–º–ø–∞–Ω–∏–∏ –∏–ª–∏ –≤ –∫–∞–∫–æ–π –∏–Ω–¥—É—Å—Ç—Ä–∏–∏ —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ–º–ø–∞–Ω–∏—è {org_name}?', 
                f'–û—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π —Å–∞–π—Ç {org_name}?'    
            ]
            qa_template=generate_qa_prompt()
            
            for key, question in zip(keys, quest):
                try: 
                    chain = await qa_rag_giga(
                    model=self.cfg.smart_llm_model,
                    qa_template=qa_template)
                    response = chain.invoke({"question": question})
                    result = response["answer"]
                    card[key]=result
                except Exception as er:
                    logger.error(er)
        except Exception as er:
            logger.error(er)   

        return card
    

    async def generate_conclusion(self, text):
        result = ""
        try:
            result = await create_chat_completion(
                model=self.cfg.fast_llm_model,
                messages=[
                    {"role": "system", "content": f"{agent_conclusion_prompt()}"},
                    {"role": "user", "content": f"{generate_conclusion_prompt(text)}"}],
                temperature=0.5,
                llm_provider=self.cfg.llm_provider,
                stream=True,
                profanity_check=False,
                verify_ssl_certs=False,
                max_tokens=self.cfg.smart_token_limit,
            )
        except Exception as e:
            logger.error(e)
        
        return result

    async def get_executive_summary(self, text):
        result = ""
        try:
            result = await create_chat_completion(
                model=self.cfg.fast_llm_model,
                messages=[
                    {"role": "system", "content": f"{agent_role_executive_summary_prompt()}"},
                    {"role": "user", "content": f"{generate_executive_summary_prompt(text)}"}],
                temperature=0.5,
                llm_provider=self.cfg.llm_provider,
                stream=True,
                profanity_check=False,
                verify_ssl_certs=False,
                max_tokens=self.cfg.smart_token_limit,
            )
        except Exception as e:
            logger.error(e)
        return result
    
    